Map-reduce

values Writable interface
keys - WitableCOmparable

user decides the file inputFormat not the number of mappers. Onnly if he overwrites and makes it to 1. 
some operations can use a combiners to reduce time. 
For example AverageReducer 

Every maps' output is in disk
When a mapper has finished and another is launched and the output is bigger than the buffer, it is written on disk.
otherwise, it is send to the reducer because more than 5% of mapers have finished.


Driver is an orchestrTION BETWWEEN mapper and Reducer.

default reducer 1. Set it with property:
-Dmapred.reduce.tasks=10

Context object is used to write the data on hdfs

The priority for the configurations depends on where they were configured:
1. default hadoop configurations
2. overwite provided configurations on the class path
3. passing the parameters dynamically at run time with -d numofReducers
4. in the code of Driver Class

We can send multiple mappers to single reducer.

data integrity
data profiling: instead of using a schema in hive we just create properties in map-reduce.


maven: dependency management install in eclipse or intellij
oozie is used for storing jars and dependencies
jenkins: is updated on svn






